{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86ccda3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kalevkim/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "path = os.getcwd()\n",
    "from classes.Block import Block #the block class\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75d93b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO (put done if it is done)\n",
    "\n",
    "#variables to create:\n",
    "#all tokens of e1: val_e1_tokens ([str]) DONE\n",
    "#all tokens of e1: val_e2_tokens [str] DONE\n",
    "#Tokens in each entityProfile of E1 ({ \"eP\": ['token1', 'token2',...'tokenN']}): dict_E1 DONE\n",
    "#Tokens in each entityProfile of E2 ({ \"eP\": ['token1', 'token2',...'tokenN']}): dict_E2 DONE\n",
    "#sets of token set(tokenE1 + tokenE2): commonToken DONE\n",
    "#Entities of E1 that contains a ct ∈ commonToken { \"cT\": [1,2,3,10,....]}: e1_dict_token DONE\n",
    "#Entities of E2 that contains a ct ∈ commonToken { \"cT\": [101,102,103,110,....]}: e2_dict_token DONE\n",
    "#Attributes of E1: all_att_e1 DONE\n",
    "#Attributes of E2: all_att_e2 DONE\n",
    "\n",
    "\n",
    "#make a class for the block: DONE\n",
    "#create the class in a seperate python file/module (?) DONE\n",
    "#Block needs a: name, ib1 (innerBlock1), ib2 (innerBlock2). if one of the ib ∈ IB is empty, a block\n",
    "#of a token should not be created\n",
    "#in addition, cardinality and block size\n",
    "\n",
    "\n",
    "#stemming and cleaning:\n",
    "#Do it at stem clean function\n",
    "# remove stop words DONE\n",
    "# stemming\n",
    "# tokenize DONE\n",
    "# DISCUSS: ignore numbers, so take only words as token, not integer\n",
    "#AND LEMMATIZATION\n",
    "#combine lowering all letters before making the token in one stem_clean function \n",
    "#so it will be easier to implement any semantic treatment\n",
    "#delete period signs\n",
    "\n",
    "#visualizatipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f495c701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f1 = open(f'{path}/data/entityCol1.json')\n",
    "f2 = open(f'{path}/data/entityCol2.json')\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "ec1 = json.load(f1)\n",
    "ec2 = json.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2243952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_clean(arr):\n",
    "    joint_words = ' '.join(arr)\n",
    "    joint_words = str(joint_words).lower()\n",
    "    val = word_tokenize(joint_words)\n",
    "    valTok = list(set([w for w in val if not w.lower() in stop_words]))\n",
    "    return valTok\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c79e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all unique key and val on both EC\n",
    "all_att_e1 = []\n",
    "all_val_e1 = []\n",
    "dict_E1 = {}\n",
    "x = 1\n",
    "for d in ec1:\n",
    "    values_EP = []\n",
    "    for key, val in (d.items()):\n",
    "        all_att_e1.append(key) #allKey\n",
    "        treatedVal = str(val).lower()\n",
    "        values_EP.append(treatedVal)\n",
    "        all_val_e1.append(treatedVal) #allVal - treat number as string\n",
    "    values_EP = stem_clean(values_EP)\n",
    "    dict_E1[x] = values_EP\n",
    "    x = x+1\n",
    "\n",
    "attE1Keys = list(set(all_att_e1))\n",
    "val_e1_tokens = list(set(stem_clean(all_val_e1)))\n",
    "\n",
    "\n",
    "all_at_e2 = [] \n",
    "all_val_e2 = []\n",
    "dict_E2 = {}\n",
    "x = 101\n",
    "for d in ec2:\n",
    "    values_EP = []\n",
    "    for key, val in (d.items()):\n",
    "        all_at_e2.append(key) #allKey\n",
    "        treatedVal = str(val).lower()\n",
    "        values_EP.append(treatedVal)\n",
    "        all_val_e2.append(treatedVal) #allVal - treat number as string\n",
    "    values_EP = stem_clean(values_EP)\n",
    "    dict_E2[x] = values_EP\n",
    "    x = x+1\n",
    "attE2Keys = list(set(all_at_e2))\n",
    "val_e2_tokens = list(set(stem_clean(all_val_e2)))\n",
    "\n",
    "\n",
    "#common token\n",
    "#Only take token that exists in both "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761bc7ec",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Token Blocking </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95240077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#common token\n",
    "#Only take token that exists in both \n",
    "common_token = set(val_e1_tokens) & set(val_e2_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ff59cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the common token create find all entity profile\n",
    "#that has contains the token\n",
    "e1_dict_token = {}\n",
    "for t in common_token:\n",
    "    x = [ ep for ep in dict_E1 if t in dict_E1[ep]]\n",
    "    e1_dict_token[t] = x\n",
    "    \n",
    "e2_dict_token = {}\n",
    "for t in common_token:\n",
    "    x = [ ep for ep in dict_E2 if t in dict_E2[ep]]\n",
    "    e2_dict_token[t] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b1ea068",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_blocks = []\n",
    "for ct in common_token:\n",
    "    new_block = Block(ct,e1_dict_token[ct], e2_dict_token[ct] )\n",
    "    all_blocks.append(new_block)\n",
    "    \n",
    "all_blocks.sort(key=lambda x: x.b_cardinality, reverse=True) #sort based on its cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1ecc949",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_name</th>\n",
       "      <th>int_b1</th>\n",
       "      <th>int_b1_size</th>\n",
       "      <th>int_b2</th>\n",
       "      <th>int_b2_size</th>\n",
       "      <th>b_cardin</th>\n",
       "      <th>b_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foundation</td>\n",
       "      <td>[10, 13, 15, 16, 43, 57, 77, 80, 83]</td>\n",
       "      <td>9</td>\n",
       "      <td>[106, 107, 125, 128, 141, 144, 152, 161, 170, ...</td>\n",
       "      <td>17</td>\n",
       "      <td>153</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>institute</td>\n",
       "      <td>[7, 12, 19, 29, 79, 82, 89, 98]</td>\n",
       "      <td>8</td>\n",
       "      <td>[104, 110, 127, 148, 159, 167, 171, 190, 194, ...</td>\n",
       "      <td>11</td>\n",
       "      <td>88</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>limited</td>\n",
       "      <td>[11, 20, 25, 38, 42, 64, 68, 87, 92]</td>\n",
       "      <td>9</td>\n",
       "      <td>[111, 116, 117, 120, 164, 168, 199, 200]</td>\n",
       "      <td>8</td>\n",
       "      <td>72</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>associates</td>\n",
       "      <td>[21, 53, 56, 58, 59, 60, 69, 73, 100]</td>\n",
       "      <td>9</td>\n",
       "      <td>[112, 121, 132, 136, 146, 162, 163, 172]</td>\n",
       "      <td>8</td>\n",
       "      <td>72</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corporation</td>\n",
       "      <td>[3, 9, 24, 26, 27, 36, 37, 39, 49, 63, 99]</td>\n",
       "      <td>11</td>\n",
       "      <td>[115, 131, 140, 181, 182, 191]</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llc</td>\n",
       "      <td>[18, 47, 62, 72, 76, 81, 94]</td>\n",
       "      <td>7</td>\n",
       "      <td>[109, 124, 126, 134, 150, 158, 169, 173, 174]</td>\n",
       "      <td>9</td>\n",
       "      <td>63</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>incorporated</td>\n",
       "      <td>[1, 6, 30, 46, 54, 84]</td>\n",
       "      <td>6</td>\n",
       "      <td>[103, 129, 138, 145, 156, 187, 188, 189]</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>industries</td>\n",
       "      <td>[5, 31, 45, 51, 52, 55, 78, 96]</td>\n",
       "      <td>8</td>\n",
       "      <td>[102, 130, 137, 143, 183, 193]</td>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ut</td>\n",
       "      <td>[10, 11, 13, 15, 16, 32, 46, 54, 62, 70, 88]</td>\n",
       "      <td>11</td>\n",
       "      <td>[106, 107, 151, 155]</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>italy</td>\n",
       "      <td>[14, 16, 22, 41, 45, 77]</td>\n",
       "      <td>6</td>\n",
       "      <td>[105, 107, 113, 135, 137, 141]</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ltd</td>\n",
       "      <td>[8, 35, 71, 74, 75, 88]</td>\n",
       "      <td>6</td>\n",
       "      <td>[123, 149, 154, 155, 165, 180]</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spain</td>\n",
       "      <td>[6, 9, 25, 49]</td>\n",
       "      <td>4</td>\n",
       "      <td>[103, 116, 133, 136, 145, 172, 173, 174]</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>female</td>\n",
       "      <td>[43, 67, 68, 69, 76, 82]</td>\n",
       "      <td>6</td>\n",
       "      <td>[104, 118, 119, 121, 127]</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mauris</td>\n",
       "      <td>[46, 71, 72]</td>\n",
       "      <td>3</td>\n",
       "      <td>[123, 124, 144, 163, 173, 175, 187]</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pc</td>\n",
       "      <td>[22, 32, 61, 93, 97]</td>\n",
       "      <td>5</td>\n",
       "      <td>[113, 133, 139, 157]</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pellentesque</td>\n",
       "      <td>[7, 23, 48, 82]</td>\n",
       "      <td>4</td>\n",
       "      <td>[104, 114, 127, 199, 200]</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>libero</td>\n",
       "      <td>[26, 27, 36, 37, 39, 49]</td>\n",
       "      <td>6</td>\n",
       "      <td>[136, 143, 178]</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>non</td>\n",
       "      <td>[7, 14, 44, 57, 79]</td>\n",
       "      <td>5</td>\n",
       "      <td>[104, 105, 149]</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nunc</td>\n",
       "      <td>[38, 42, 60]</td>\n",
       "      <td>3</td>\n",
       "      <td>[117, 150, 164, 175, 178]</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sed</td>\n",
       "      <td>[5, 78]</td>\n",
       "      <td>2</td>\n",
       "      <td>[102, 141, 150, 154, 165, 178, 181]</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      block_name                                        int_b1  int_b1_size  \\\n",
       "0     foundation          [10, 13, 15, 16, 43, 57, 77, 80, 83]            9   \n",
       "1      institute               [7, 12, 19, 29, 79, 82, 89, 98]            8   \n",
       "2        limited          [11, 20, 25, 38, 42, 64, 68, 87, 92]            9   \n",
       "3     associates         [21, 53, 56, 58, 59, 60, 69, 73, 100]            9   \n",
       "4    corporation    [3, 9, 24, 26, 27, 36, 37, 39, 49, 63, 99]           11   \n",
       "5            llc                  [18, 47, 62, 72, 76, 81, 94]            7   \n",
       "6   incorporated                        [1, 6, 30, 46, 54, 84]            6   \n",
       "7     industries               [5, 31, 45, 51, 52, 55, 78, 96]            8   \n",
       "8             ut  [10, 11, 13, 15, 16, 32, 46, 54, 62, 70, 88]           11   \n",
       "9          italy                      [14, 16, 22, 41, 45, 77]            6   \n",
       "10           ltd                       [8, 35, 71, 74, 75, 88]            6   \n",
       "11         spain                                [6, 9, 25, 49]            4   \n",
       "12        female                      [43, 67, 68, 69, 76, 82]            6   \n",
       "13        mauris                                  [46, 71, 72]            3   \n",
       "14            pc                          [22, 32, 61, 93, 97]            5   \n",
       "15  pellentesque                               [7, 23, 48, 82]            4   \n",
       "16        libero                      [26, 27, 36, 37, 39, 49]            6   \n",
       "17           non                           [7, 14, 44, 57, 79]            5   \n",
       "18          nunc                                  [38, 42, 60]            3   \n",
       "19           sed                                       [5, 78]            2   \n",
       "\n",
       "                                               int_b2  int_b2_size  b_cardin  \\\n",
       "0   [106, 107, 125, 128, 141, 144, 152, 161, 170, ...           17       153   \n",
       "1   [104, 110, 127, 148, 159, 167, 171, 190, 194, ...           11        88   \n",
       "2            [111, 116, 117, 120, 164, 168, 199, 200]            8        72   \n",
       "3            [112, 121, 132, 136, 146, 162, 163, 172]            8        72   \n",
       "4                      [115, 131, 140, 181, 182, 191]            6        66   \n",
       "5       [109, 124, 126, 134, 150, 158, 169, 173, 174]            9        63   \n",
       "6            [103, 129, 138, 145, 156, 187, 188, 189]            8        48   \n",
       "7                      [102, 130, 137, 143, 183, 193]            6        48   \n",
       "8                                [106, 107, 151, 155]            4        44   \n",
       "9                      [105, 107, 113, 135, 137, 141]            6        36   \n",
       "10                     [123, 149, 154, 155, 165, 180]            6        36   \n",
       "11           [103, 116, 133, 136, 145, 172, 173, 174]            8        32   \n",
       "12                          [104, 118, 119, 121, 127]            5        30   \n",
       "13                [123, 124, 144, 163, 173, 175, 187]            7        21   \n",
       "14                               [113, 133, 139, 157]            4        20   \n",
       "15                          [104, 114, 127, 199, 200]            5        20   \n",
       "16                                    [136, 143, 178]            3        18   \n",
       "17                                    [104, 105, 149]            3        15   \n",
       "18                          [117, 150, 164, 175, 178]            5        15   \n",
       "19                [102, 141, 150, 154, 165, 178, 181]            7        14   \n",
       "\n",
       "    b_size  \n",
       "0       26  \n",
       "1       19  \n",
       "2       17  \n",
       "3       17  \n",
       "4       17  \n",
       "5       16  \n",
       "6       14  \n",
       "7       14  \n",
       "8       15  \n",
       "9       12  \n",
       "10      12  \n",
       "11      12  \n",
       "12      11  \n",
       "13      10  \n",
       "14       9  \n",
       "15       9  \n",
       "16       9  \n",
       "17       8  \n",
       "18       8  \n",
       "19       9  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFrame for purpose Visualization Purpose\n",
    "token_blocks_df = pd.DataFrame([x.as_dict() for x in all_blocks])\n",
    "token_blocks_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d77836",
   "metadata": {},
   "source": [
    "<h3>Attribute Clustering</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf61fd91",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41161a4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e2154a701d36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mattribute_blocks_ec2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattE1Keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mattribute_blocks_ec1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstem_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0matt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mec1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0matt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattE2Keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mattribute_blocks_ec2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstem_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0matt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mec2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0matt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-e2154a701d36>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mattribute_blocks_ec2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattE1Keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mattribute_blocks_ec1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstem_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0matt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mec1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0matt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattE2Keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mattribute_blocks_ec2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstem_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0matt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mec2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0matt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "It's not finished yet, please do not proceed, let me finish it on Monday. :D\n",
    "\"\"\"\n",
    "\n",
    "#Group based on the attribute for E1\n",
    "#Group based on the attribute for E2\n",
    "\"\"\"attE1Keys.remove('id')\n",
    "attE2Keys.remove('id')\n",
    "attE2Keys.remove('age')\"\"\"\n",
    "\n",
    "attribute_blocks_ec1 = {}\n",
    "attribute_blocks_ec2 = {}\n",
    "for attribute in attE1Keys:\n",
    "    attribute_blocks_ec1[attribute] = stem_clean(word_tokenize(' '.join(set([att[attribute].lower() for att in ec1 if attribute in att.keys()]))))\n",
    "for attribute in attE2Keys:\n",
    "    attribute_blocks_ec2[attribute] = stem_clean(word_tokenize(' '.join(set([att[attribute].lower() for att in ec2 if attribute in att.keys()]))))\n",
    "\n",
    "#Similarity Calculation\n",
    "\n",
    "def jaccard_set(list1, list2):\n",
    "    \"\"\"Define Jaccard Similarity function for two sets\"\"\"\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "sim_ec1_ec2 = {}\n",
    "for each in attribute_blocks_ec1:\n",
    "    temp = []\n",
    "    for every in attribute_blocks_ec2:\n",
    "        similarity = jaccard_set(attribute_blocks_ec1[each], attribute_blocks_ec2[every])\n",
    "        if similarity > 0:\n",
    "            temp.append(every)\n",
    "    sim_ec1_ec2[each] = temp\n",
    "\n",
    "sim_ec2_ec1 = {}\n",
    "for each in attribute_blocks_ec2:\n",
    "    temp = []\n",
    "    for every in attribute_blocks_ec1:\n",
    "        similarity = jaccard_set(attribute_blocks_ec2[each], attribute_blocks_ec1[every])\n",
    "        if similarity > 0:\n",
    "            temp.append(every)\n",
    "    sim_ec2_ec1[each] = temp\n",
    "\n",
    "#Attribute Blocking\n",
    "\n",
    "\n",
    "#testa = jaccard_set(attribute_blocks_ec1['domicile'], attribute_blocks_ec2['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f9c4086",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sim_ec2_ec1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d6a3c1d1b179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msim_ec2_ec1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sim_ec2_ec1' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2cb4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
